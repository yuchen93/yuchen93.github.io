<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Yuchen Cui     </title>
<!--
Neaty HTML Template
https://www.templatemo.com/tm-501-neaty
-->
    <!-- load stylesheets -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,400">  <!-- Google web font "Open Sans" -->
    <link rel="stylesheet" href="css/bootstrap.min.css">                                      <!-- Bootstrap style -->
    <link rel="stylesheet" href="css/magnific-popup.css">                                <!-- Magnific pop up style, https://dimsemenov.com/plugins/magnific-popup/ -->
    <link rel="stylesheet" href="css/templatemo-style.css">                                   <!-- Templatemo style -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
          <![endif]-->
    <style>
	  .container {
	  display: flex;
	  align-items: center;
	  justify-content: center
	}

	img {
	  max-width: 100%;
	  max-height:100%;
	}

	.text {
	  font-size: 20px;
	  padding-left: 20px;
	}
    </style>
</head>
    <body>        
        <div class="container">
            <div class="row">
                <div class="tm-left-right-container">
                    <!-- Left column: logo and menu -->
                    <div class="tm-blue-bg tm-left-column">                        
                        <div class="tm-logo-div text-xs-center">
                            <img src="images/profile_yuchen.jpg" alt="yuchen" 
    style="width:200px;">
                            <h1 class="tm-site-name">Yuchen Cui</h1>
                   <h6>          <br>
     <b>Email</b>: yuchencui [at] cs.ucla.edu <br><br>
<a href='CV.pdf'><u>Curriculum Vitae</a> <br>
<a href='https://scholar.google.com/citations?user=qQz2cm8AAAAJ&hl=en'>GoogleScholar</a> <br>
<a href='https://www.linkedin.com/in/yuchen-cui-4702a548/'>LinkedIn</u></a>   <br>
    </p> </h6>
    
                        </div>
                        <nav class="tm-main-nav">
                            <ul class="tm-main-nav-ul">
                                <li class="tm-nav-item">
                                    <a href="#about" class="tm-nav-item-link">About Me</a>
                                </li>
                                <li class="tm-nav-item">
                                    <a href="#publications" class="tm-nav-item-link">Publications</a>
                                </li>    
                            </ul>
                        </nav>                                         
                    </div> <!-- Left column: logo and menu -->
                    
                    <!-- Right column: content -->
                    <div class="tm-right-column">
                     

                        <div class="tm-content-div">
                            <!-- Welcome section -->
                            <section id="about" class="tm-section">
                                <header>
                                    <h2 class="tm-blue-text tm-welcome-title tm-margin-b-45">Hi, I'm Yuchen!</h2>
                                </header>
                               
                               <p> 
            I am an Assitant Professor in Computer Science at UCLA. My research interest lies in the intersection of robot learning and human-robot interaction. 
			      Human guidance is essential for equipping robots with the ability to learn new skills and adapt to diverse users after deployment, but teaching robots is not trivial for non-expert users. 
            My research goal is to develop algorithms, frameworks, and systems that enable robots to efficiently learn from interactions with humans. <br><br>
                               
			      Prior to UCLA, I was an <a href='https://hai.stanford.edu/'>HAI</a> postdoc fellow in the <a href='https://iliad.stanford.edu/'>ILIAD lab</a>, advised by <a href='https://dorsa.fyi/'>Dorsa Sadigh</a> at Stanford University. 
			      I received my PhD from the <a href='https://www.cs.utexas.edu/'>University of Texas at Austin</a> in 2021, advised by <a href='https://people.cs.umass.edu/~sniekum/'>Scott Niekum </a>.

			       <br><br>
			       
             I am hiring PhD students for Fall 2025! <br><br>
    
    
    
    </p>
    
                            </section>
                            
                          


  <!-- publications section -->
                            <section id="publications" class="tm-section">
                                <div class="row">                                                                
                                    
                                        <header>
                                            <h2 class="tm-blue-text tm-section-title">Publications</h2>
                                        </header>
                                        <br>
                                      
    
  
   
<h4>Selected Publications</h4>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

	   <tr>
            <td style="padding:1%;width:25%;vertical-align:middle;min-width:200px">
	     <img src="images/DROC.png" alt="" style="width:250px; height:auto; max-width:100%;" />
            </td>
            <td style="padding:1%;width:75%;vertical-align:middle">
              <h5><b>Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections</b></h5>
              L. Zha, <u>Y. Cui</u>, L. Lin, M. Kwon, M. G. Arenas, A. Zeng, F. Xia, D. Sadigh <br>
	      International Conference on Robotics and Automation (ICRA), May 2024
              <br>
              <a href="https://arxiv.org/abs/2311.10678"><i class="fa fa-code" aria-hidden="true"></i> paper  &nbsp;</a>
              <a href="https://sites.google.com/stanford.edu/droc"><i class="fa fa-users" aria-hidden="true"></i> project &nbsp; </a>
              <p></p>
            </td>
          </tr>

	 <tr>
            <td style="padding:1%;width:25%;vertical-align:middle;min-width:200px">
              <img src="images/HYDRA_CoRL23.gif" alt="" style="width:250px; height:auto; max-width:100%;" />
            </td>
            <td style="padding:1%;width:75%;vertical-align:middle">
              <h5><b>HYDRA: Hybrid Robot Actions for Imitation Learning</b></h5>
	      S. Belkhale, <u>Y. Cui</u>, D. Sadigh <br>
	      Conference on Robot Learning (CoRL), November 2023
              <br>
              <a href="https://arxiv.org/abs/2306.17237"><i class="fa fa-code" aria-hidden="true"></i> paper  &nbsp;</a>
              <a href="https://sites.google.com/view/hydra-il-2023"><i class="fa fa-users" aria-hidden="true"></i> project &nbsp; </a>
              <p></p>
            </td>
          </tr>

	 <tr>
            <td style="padding:1%;width:25%;vertical-align:middle;min-width:200px">
              <img src="images/GIRAF_drawers.gif" alt="" style="width:250px; height:auto; max-width:100%;" />
            </td>
            <td style="padding:1%;width:75%;vertical-align:middle">
              <h5><b>Gesture-Informed Robot Assistance via Foundation Model</b></h5>
	      L. Lin, <u>Y. Cui</u>, Y. Hao, F. Xia, D. Sadigh <br>
	      Conference on Robot Learning (CoRL), November 2023
              <br>
              <a href="https://arxiv.org/abs/2309.02721"><i class="fa fa-code" aria-hidden="true"></i> paper  &nbsp;</a>
              <a href="https://sites.google.com/view/giraf23"><i class="fa fa-users" aria-hidden="true"></i> project &nbsp; </a>
              <p></p>
            </td>
          </tr>

         <tr>
            <td style="padding:1%;width:25%;vertical-align:middle;min-width:200px">
              <img src="images/data_quality.png" alt="" style="width:250px; height:auto; max-width:100%;" />
            </td>
            <td style="padding:1%;width:75%;vertical-align:middle">
              <h5><b>Data Quality in Imitation Learning</b></h5>
	      S. Belkhale, <u>Y. Cui</u>, D. Sadigh <br>
              Conference on Neural Information Processing System (NeurIPS), December 2023
              <br>
              <a href="https://arxiv.org/abs/2306.02437"><i class="fa fa-code" aria-hidden="true"></i> paper  &nbsp;</a>
              <p></p>
            </td>
          </tr>
	  

	  <tr>
            <td style="padding:1%;width:25%;vertical-align:middle;min-width:200px">
              <img src="images/LILAC.png" alt="" style="width:250px; height:auto; max-width:100%;" />
            </td>
            <td style="padding:1%;width:75%;vertical-align:middle">
              <h5><b>"No, to the Right" â€“ Online Language Corrections for Robotic Manipulation via Shared Autonomy</b></h5>
              <u>Y. Cui*</u>,   S. Karamcheti*, R. Palleti, N. Shivakumar, P. Liang, D. Sadigh<br>
              International Conference on Human-Robot Interaction (HRI), March 2023
              <br>
              <a href="https://arxiv.org/abs/2301.02555"><i class="fa fa-code" aria-hidden="true"></i> paper  &nbsp;</a>
	      <a href="https://sites.google.com/view/hri-lilac"><i class="fa fa-users" aria-hidden="true"></i> project &nbsp; </a>
              <p></p>
            </td>
          </tr>

	  <tr>
            <td style="padding:1%;width:25%;vertical-align:middle;min-width:200px">
              <img src="images/MIL.png" alt="" style="width:250px; height:auto; max-width:100%;" />
            </td>
            <td style="padding:1%;width:75%;vertical-align:middle">
              <h5><b>Masked Imitation Learning: Discovering Environment-Invariant Modalities in Multimodal Demonstrations</b></h5>
              Y. Hao*, R. Wang*, Z. Cao, Z. Wang, <u>Y. Cui</u>, D. Sadigh<br>
              International Conference on Intelligent Robots and Systems (IROS), October 2023
              <br>
              <a href="https://arxiv.org/abs/2209.07682"><i class="fa fa-code" aria-hidden="true"></i> paper  &nbsp;</a>
              <p></p>
            </td>
          </tr>


	  <tr>
            <td style="padding:1%;width:25%;vertical-align:middle;min-width:200px">
              <img src="images/ZeST.png" alt="" style="width:250px; height:auto; max-width:100%;" />
            </td>
            <td style="padding:1%;width:75%;vertical-align:middle">
              <h5><b>Can Foundation Models Perform Zero-Shot Task Specification For Robot Manipulation?</b></h5>
	      <u>Y. Cui</u>,  S. Niekum, A. Gupta, V. Kumar, A. Rajeswaran <br>
              Learning for Dynamics & Control Conference (L4DC), June 2022
              <br>
              <a href="https://arxiv.org/abs/2204.11134"><i class="fa fa-code" aria-hidden="true"></i> paper  &nbsp;</a>
              <p></p>
            </td>
          </tr>

	  <tr>
            <td style="padding:1%;width:25%;vertical-align:middle;min-width:200px">
              <img src="images/EMPATHIC.gif" alt="" style="width:250px; height:auto; max-width:100%;" />
            </td>
            <td style="padding:1%;width:75%;vertical-align:middle">
              <h5><b>The EMPATHIC Framework for Task Learning from Implicit Human Feedback</b></h5>
	       <u>Y. Cui</u>, Q. Zhang, A. Allievi, P. Stone, S. Niekum, and W. Knox<br>
              Conference on Robot Learning (CoRL), Nov 2020
              <br>
              <a href="https://arxiv.org/abs/2009.13649"><i class="fa fa-code" aria-hidden="true"></i> paper  &nbsp;</a>
              <a href="https://sites.google.com/utexas.edu/empathic"><i class="fa fa-users" aria-hidden="true"></i> project  &nbsp;</a>
              <p></p>
            </td>
          </tr>

	  <tr>
            <td style="padding:1%;width:25%;vertical-align:middle;min-width:200px">
              <img src="images/UAIL.gif" alt="" style="width:250px; height:auto; max-width:100%;" />
            </td>
            <td style="padding:1%;width:75%;vertical-align:middle">
              <h5><b>Uncertainty-Aware Data Aggregation for Deep Imitation Learning</b></h5>
	      <u>Y. Cui</u>, D. Isele, S. Niekum and K. Fujimura<br>
	      International Conference on Robotics and Automation (ICRA), May 2019
              <br>
              <a href="https://arxiv.org/abs/1905.02780"><i class="fa fa-code" aria-hidden="true"></i> paper  &nbsp;</a>
              <p></p>
            </td>
          </tr>

	  <tr>
            <td style="padding:1%;width:25%;vertical-align:middle;min-width:200px">
              <img src="images/ARC_new.png" alt="" style="width:250px; height:auto; max-width:100%;" />
            </td>
            <td style="padding:1%;width:75%;vertical-align:middle">
              <h5><b>Active Reward Learning from Critiques</b></h5>
	      <u>Y. Cui</u> and S. Niekum<br>
	      International Conference on Robotics and Automation (ICRA), May 2018
              <br>
              <a href="https://ieeexplore.ieee.org/document/8460854"><i class="fa fa-code" aria-hidden="true"></i> paper  &nbsp;</a>
              <p></p>
            </td>
          </tr>

	  </table>

	  <br>
<h4>Other Conference & Journal Publications</h4>
 <ul> 

    <li><b> <a href='hil_ml_survey_ijcai_2021.pdf'>Understanding the Relationship between Interactions and Outcomes in Human-in-the-Loop Machine Learning</a> </b> <u>Y. Cui</u>, P. Koppol, H. Admoni, S. Niekum, R. Simmons, A. Steinfeld, T. Fitzgerald. Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI, Survey Track). Aug 2021.</li>
    <li><b> <a href='https://arxiv.org/abs/1901.02161'>Risk-Aware Active Inverse Reinforcement Learning</a> </b> <u>Y. Cui</u>, D. Brown and S. Niekum. Proceedings of the 2nd Annual Conference on Robot Learning (CoRL), Oct. 2018.  </li>
    <li><b><a href='https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006518'>Modeling Sensory-Motor Decisions in Natural Behavior</a></b> R. Zhang, S. Zhang, M. H. Tong, <u>Y. Cui</u>, C. A. Rothkopf, D. H. Ballard and M. M. Hayhoe. PLOS Computational Biology, Oct 2018.
    <li><b> <a href='https://dl.acm.org/citation.cfm?id=3081362'>Indoor Follow Me Drone</a></b> W. Mao, Z. Zhang, L. Qiu, J. He, <u>Y. Cui</u>, and S. Yun. Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services, June, 2017. </li>
    </ul>
    <br>
    
    
    <h4>Workshop Publications</h4>
   <ul>
	   <li><b><a href='https://arxiv.org/abs/2311.10678'>Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections</a></b> L. Zha, <u>Y. Cui</u>, L. Lin, M. Kwon, M. G. Arenas, A. Zeng, F. Xia, D. Sadigh. 2nd Workshop on Language and Robot Learning: Language as Grounding @ CoRL, Nov. 2023.
	   </li>
   <li><b><a href='https://iliad.stanford.edu/pdfs/publications/karamcheti2022lilac.pdf'> Shared Autonomy for Robotic Manipulation with Language Corrections</a></b> S. Karamcheti*, R. Palleti*, <u>Y. Cui</u>, P. Liang, D. Sadigh. Workshop on Learning with Natural Language Supervision @ ACL, May 2022. </li>
   <li><b><a href='./icml21ssl.pdf'>Aux-AIRL: End-to-End Self-Supervised Reward Learning for Extrapolating beyond Suboptimal Demonstrations</a></b> <u>Y. Cui</u>, B. Liu, A. Saran, S. Giguere, P. Stone, and S. Niekum. ICML Workshop on Self-Supervised Learning for Reasoning and Perception, July 2021. </li>
   <li><b><a href='https://drive.google.com/file/d/1EyssrCVd8XaJFUkKj3sDSz2hMP_F1eki/view?usp=sharing'>Reaction Modeling for Deriving General Task Information from Implicit Human Feedback</a></b> <u>Y. Cui</u>, Q. Zhang, S. Jain, A. Allievi, P. Stone, S. Niekum, and W. Knox. HRI Workshop on Exploring Applications for Autonomous Non-Verbal Human-Robot Interactions, Mar 2021. </li>
    <li><b> <a href='https://www.cs.utexas.edu/~sniekum/pubs/CuiRSS2017.pdf'>Active Learning from Critiques via Bayesian Inverse Reinforcement Learning</a> </b> <u>Y. Cui</u> and S. Niekum. Rotics: Science and Systems (R:SS) Workshop on Mathematical Models, Algorithms, and Human-Robot Interaction, July 2017. </li>
    <li><b> <a href='https://diglib.eg.org/handle/10.2312/eurova.20151102.043-047'>Trajectory-based visual analytics for anomalous human movement analysis using social media</a></b> J. Chae, <u>Y. Cui</u>, Y. Jang, G. Wang, A. Malik, D.S. Ebert. EuroVis Workshop on Visual Analytics (EuroVA), May, 2015.  </li>
     </ul>
                                       
                                       
                                   
                                  
                                </div>                            
                            </section>  
                            
                        
                            <footer>
                                <span style="color:gray; font-size:13px;"> <p class="tm-copyright-p"> &copy; <script>document.write((new Date()).getFullYear());</script> Yuchen Cui 
                              | Modified from template designed by <a href='https://templatemo.com/'>TemplateMo</a> </p> 
                                </span>
                            </footer>
                        </div>  
                        
                    </div> <!-- Right column: content -->
                </div>
            </div> <!-- row -->
        </div> <!-- container -->
                
        <!-- load JS files -->
        <script src="js/jquery-1.11.3.min.js"></script>             <!-- jQuery (https://jquery.com/download/) -->
        <script src="js/jquery.magnific-popup.min.js"></script>     <!-- Magnific pop-up (https://dimsemenov.com/plugins/magnific-popup/) -->
        <script src="js/jquery.singlePageNav.min.js"></script>      <!-- Single Page Nav (https://github.com/ChrisWojcik/single-page-nav) -->
        <script>     
       
            $(document).ready(function(){

                // Single page nav
                $('.tm-main-nav').singlePageNav({
                    'currentClass' : "active",
                    offset : 20
                });

                // Magnific pop up
                $('.tm-gallery-1').magnificPopup({
                  delegate: 'a', // child items selector, by clicking on it popup will open
                  type: 'image',
                  gallery: {enabled:true}
                  // other options
                }); 

                $('.tm-gallery-2').magnificPopup({
                  delegate: 'a', // child items selector, by clicking on it popup will open
                  type: 'image',
                  gallery: {enabled:true}
                  // other options
                }); 

                $('.tm-gallery-3').magnificPopup({
                  delegate: 'a', // child items selector, by clicking on it popup will open
                  type: 'image',
                  gallery: {enabled:true}
                  // other options
                }); 

                $('.tm-current-year').text(new Date().getFullYear());                
            });
        </script>             
</body>
</html>
